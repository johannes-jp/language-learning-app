- flashcards both ways
	- seeing sentences that contain the word
		- option: also show sentences containing root(s) of the word
- sentence translation both ways
- for fill-in-the-blank, show diff between the original sentence and the user sentence and prompt them with 'easy' 'medium' 'hard' to decide for themselves 
- conversation
	- pretend I'm speaking natively
	- 
- changing the priority list
	- priority list has options for statistical normalization
		- frequency list
			- zipfian distribution - steep dropoff of usage
				- ex. most used word is used twice as often as next used word, and there are lots of 'rare events' (words not commonly used) and few very common ones
		- ranked list
			- 
- changing learning weights
- lessons
	- curated learning experiences
	- top X words from frequency list
- auto-build sentences for important words that don't have enough example usage
- sentence selection algorithm
	- theory
		- it shouldn't serve sentences where you know 5/6 words well, that's boring and no different from flashcards & vocab
		- it **should** serve sentences where
			- you know 5/6 words but not very well
				- `# of words / sum of SR intervals of those words` or a similar regression that accounts for the SR algorithm
			- you only know 1 or 2 weird words really well
				- the words you don't know should have high relevance
				- the words you do know should have low relevance
		- this is why we still need a type-specific SR, that's the only way people are going to inadvertently learn unusual words - because they've seen them in a sentence
	- in a new sentence, any word with an sr interval is 1 and any word without is 0. 
	- divide each word's relevance by their SR interval and add
- user generated content from lists is flagged as such, but with a verified source of truth or enough upvotes, it can be added to master content lists
- linguistics.stackexchange integration?